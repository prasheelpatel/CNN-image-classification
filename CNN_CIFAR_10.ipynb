{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_Pz_FqoGpEp"
      },
      "source": [
        "# CNN for image classification in CIFAR-10<br>\n",
        "CIFAR-10 : Consists 60000 32x32 color images in 10 classes, with 6000 images/class (50000 training and 10000 test).\n",
        "10 classes :\n",
        "<ol start=\"0\">\n",
        "<li> airplane\n",
        "<li>  automobile\n",
        "<li> bird\n",
        "<li>  cat\n",
        "<li> deer\n",
        "<li> dog\n",
        "<li>  frog\n",
        "<li>  horse\n",
        "<li>  ship\n",
        "<li>  truck\n",
        "</ol>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "scrolled": true,
        "id": "t5p-XgClGpEq"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "J7Kx8XNNGpEs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b3eac39-bcbe-4193-d708-98d52df466a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9K3xHC6jGpEt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9a77aaf-6eb6-45ac-a515-1cd2d64ee464"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "#32 x 32 x 3 numpy array\n",
        "x_train[333].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dIMkMIdRGpEt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "500b5900-c525-4535-a025-b3f0cec67843"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# view an image\n",
        "print(y_train[333])\n",
        "plt.imshow(x_train[333]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jytxFZtCGpEu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a605ddd0-4b58-49ab-bf16-0b78c2a20d1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# classes to 1X10 matrix\n",
        "num_classes = 10\n",
        "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
        "# sample test\n",
        "y_train[333]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AsQ3Xwh8GpEu"
      },
      "outputs": [],
      "source": [
        "# scale\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "std = np.std(x_train,axis=(0,1,2,3))\n",
        "\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RTIixafGpEw"
      },
      "source": [
        "## model_1: Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "3Cj2C1sDGpEw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb4fbd99-bc7d-4bb9-adb0-2579e62b75a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 32)        2432      \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 6, 6, 32)          25632     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 3, 3, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 3, 3, 32)          0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 288)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 512)               147968    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 181,162\n",
            "Trainable params: 181,162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_1 = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(32, kernel_size=5, activation='relu', strides = (2,2), padding='same',input_shape=x_train.shape[1:]), \n",
        "    keras.layers.Conv2D(32, kernel_size=5, activation='relu', strides = (2,2), ), \n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)), \n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Flatten(),  \n",
        "    keras.layers.Dense(512, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(num_classes, activation='softmax'), \n",
        "])\n",
        "model_1.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "aQqM11OCGpEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7fc9f3b-adde-494d-ecc1-e696c6f29925"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.7356 - accuracy: 0.3679 - val_loss: 1.4365 - val_accuracy: 0.4837\n",
            "Epoch 2/15\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.4515 - accuracy: 0.4796 - val_loss: 1.3122 - val_accuracy: 0.5268\n",
            "Epoch 3/15\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.3353 - accuracy: 0.5222 - val_loss: 1.2252 - val_accuracy: 0.5648\n",
            "Epoch 4/15\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.2605 - accuracy: 0.5495 - val_loss: 1.1448 - val_accuracy: 0.5964\n",
            "Epoch 5/15\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.2023 - accuracy: 0.5698 - val_loss: 1.1215 - val_accuracy: 0.6030\n",
            "Epoch 6/15\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.1575 - accuracy: 0.5877 - val_loss: 1.1432 - val_accuracy: 0.5959\n",
            "Epoch 7/15\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.1163 - accuracy: 0.6046 - val_loss: 1.0570 - val_accuracy: 0.6247\n",
            "Epoch 8/15\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.0880 - accuracy: 0.6147 - val_loss: 1.0331 - val_accuracy: 0.6379\n",
            "Epoch 9/15\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.0633 - accuracy: 0.6210 - val_loss: 1.0167 - val_accuracy: 0.6438\n",
            "Epoch 10/15\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.0343 - accuracy: 0.6340 - val_loss: 1.0154 - val_accuracy: 0.6440\n",
            "Epoch 11/15\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.0086 - accuracy: 0.6443 - val_loss: 0.9485 - val_accuracy: 0.6735\n",
            "Epoch 12/15\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.9857 - accuracy: 0.6532 - val_loss: 0.9309 - val_accuracy: 0.6765\n",
            "Epoch 13/15\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.9655 - accuracy: 0.6581 - val_loss: 0.9413 - val_accuracy: 0.6703\n",
            "Epoch 14/15\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.9469 - accuracy: 0.6658 - val_loss: 0.9218 - val_accuracy: 0.6769\n",
            "Epoch 15/15\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.9332 - accuracy: 0.6725 - val_loss: 0.9167 - val_accuracy: 0.6838\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcb075e0590>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "batch_size = 128\n",
        "\n",
        "opt = RMSprop(learning_rate=0.0005, decay=1e-6)\n",
        "\n",
        "model_1.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_1.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=15,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "OL5IoMLUGpEy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48321968-2846-44ed-8be9-3abf8fc48512"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.9167316555976868\n",
            "Test accuracy: 0.6837999820709229\n"
          ]
        }
      ],
      "source": [
        "score = model_1.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "9H6h9Dk2GpEy"
      },
      "source": [
        "## model_2: Conv -> Conv -> MaxPool -> Conv -> Conv -> MaxPool -> Conv -> Conv -> MaxPool ->(Flatten) -> Dense -> Final Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "o_2BrHgfsNn4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1515a4f1-bfcb-4838-a6a9-5a50b2f2b2ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_10 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 309,290\n",
            "Trainable params: 308,394\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "wdecay=1e-4\n",
        "model_2 = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(32, kernel_size=3,padding='same', activation='relu',kernel_regularizer=keras.regularizers.l2(wdecay), input_shape=x_train.shape[1:]), \n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(32, kernel_size=3,padding='same', activation='relu',kernel_regularizer=keras.regularizers.l2(wdecay)), \n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)), \n",
        "    keras.layers.Dropout(0.2),\n",
        "\n",
        "    keras.layers.Conv2D(64, kernel_size=3,padding='same', activation='relu',kernel_regularizer=keras.regularizers.l2(wdecay)), \n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(64, kernel_size=3,padding='same', activation='relu',kernel_regularizer=keras.regularizers.l2(wdecay)), \n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)), \n",
        "    keras.layers.Dropout(0.3),\n",
        "\n",
        "    keras.layers.Conv2D(128, kernel_size=3,padding='same', activation='relu',kernel_regularizer=keras.regularizers.l2(wdecay)), \n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(128, kernel_size=3,padding='same', activation='relu',kernel_regularizer=keras.regularizers.l2(wdecay)), \n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)), \n",
        "    keras.layers.Dropout(0.4),\n",
        "    \n",
        "    keras.layers.Flatten(), \n",
        "    keras.layers.Dense(num_classes, activation='softmax'),\n",
        "])\n",
        "model_2.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdMS4C0IGpEz",
        "outputId": "d376c06a-2323-4a16-8858-c66585011199"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "781/781 [==============================] - 35s 43ms/step - loss: 1.4239 - accuracy: 0.5467 - val_loss: 1.3129 - val_accuracy: 0.6013 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 1.1372 - accuracy: 0.6366 - val_loss: 1.0492 - val_accuracy: 0.6782 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "781/781 [==============================] - 28s 35ms/step - loss: 0.9981 - accuracy: 0.6812 - val_loss: 0.9814 - val_accuracy: 0.7081 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.9142 - accuracy: 0.7115 - val_loss: 0.7970 - val_accuracy: 0.7574 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.8649 - accuracy: 0.7287 - val_loss: 0.7825 - val_accuracy: 0.7641 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.8287 - accuracy: 0.7449 - val_loss: 0.7536 - val_accuracy: 0.7757 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.8050 - accuracy: 0.7559 - val_loss: 0.8029 - val_accuracy: 0.7704 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.7798 - accuracy: 0.7667 - val_loss: 0.7481 - val_accuracy: 0.7836 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.7560 - accuracy: 0.7784 - val_loss: 0.7422 - val_accuracy: 0.7909 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.7459 - accuracy: 0.7830 - val_loss: 0.7419 - val_accuracy: 0.7936 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.7345 - accuracy: 0.7887 - val_loss: 0.6986 - val_accuracy: 0.8097 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.7194 - accuracy: 0.7972 - val_loss: 0.6469 - val_accuracy: 0.8250 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.7091 - accuracy: 0.8000 - val_loss: 0.6808 - val_accuracy: 0.8168 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.7019 - accuracy: 0.8033 - val_loss: 0.7319 - val_accuracy: 0.8051 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.6958 - accuracy: 0.8065 - val_loss: 0.6851 - val_accuracy: 0.8225 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.6847 - accuracy: 0.8109 - val_loss: 0.6675 - val_accuracy: 0.8242 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.6782 - accuracy: 0.8143 - val_loss: 0.6537 - val_accuracy: 0.8279 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.6756 - accuracy: 0.8170 - val_loss: 0.6579 - val_accuracy: 0.8289 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.6702 - accuracy: 0.8196 - val_loss: 0.6545 - val_accuracy: 0.8326 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.6700 - accuracy: 0.8198 - val_loss: 0.6475 - val_accuracy: 0.8393 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6593 - accuracy: 0.8235 - val_loss: 0.6270 - val_accuracy: 0.8403 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.6601 - accuracy: 0.8246 - val_loss: 0.6481 - val_accuracy: 0.8374 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.6565 - accuracy: 0.8243 - val_loss: 0.6459 - val_accuracy: 0.8341 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.6515 - accuracy: 0.8275 - val_loss: 0.6604 - val_accuracy: 0.8344 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6485 - accuracy: 0.8296 - val_loss: 0.6199 - val_accuracy: 0.8449 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.6441 - accuracy: 0.8323 - val_loss: 0.6529 - val_accuracy: 0.8336 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.6397 - accuracy: 0.8319 - val_loss: 0.6383 - val_accuracy: 0.8426 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.6406 - accuracy: 0.8341 - val_loss: 0.7247 - val_accuracy: 0.8164 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.6415 - accuracy: 0.8312 - val_loss: 0.6837 - val_accuracy: 0.8285 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.6361 - accuracy: 0.8360 - val_loss: 0.6439 - val_accuracy: 0.8412 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6360 - accuracy: 0.8342 - val_loss: 0.6415 - val_accuracy: 0.8426 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.5869 - accuracy: 0.8527 - val_loss: 0.5625 - val_accuracy: 0.8654 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5741 - accuracy: 0.8564 - val_loss: 0.5479 - val_accuracy: 0.8690 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5550 - accuracy: 0.8586 - val_loss: 0.5774 - val_accuracy: 0.8615 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5476 - accuracy: 0.8610 - val_loss: 0.5583 - val_accuracy: 0.8679 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5396 - accuracy: 0.8634 - val_loss: 0.5733 - val_accuracy: 0.8596 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.5388 - accuracy: 0.8623 - val_loss: 0.5810 - val_accuracy: 0.8572 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5323 - accuracy: 0.8637 - val_loss: 0.5258 - val_accuracy: 0.8730 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5297 - accuracy: 0.8623 - val_loss: 0.5681 - val_accuracy: 0.8606 - lr: 5.0000e-04\n",
            "Epoch 40/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5251 - accuracy: 0.8642 - val_loss: 0.5273 - val_accuracy: 0.8703 - lr: 5.0000e-04\n",
            "Epoch 41/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.5185 - accuracy: 0.8639 - val_loss: 0.5310 - val_accuracy: 0.8696 - lr: 5.0000e-04\n",
            "Epoch 42/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.5169 - accuracy: 0.8654 - val_loss: 0.5397 - val_accuracy: 0.8694 - lr: 5.0000e-04\n",
            "Epoch 43/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5170 - accuracy: 0.8654 - val_loss: 0.5746 - val_accuracy: 0.8579 - lr: 5.0000e-04\n",
            "Epoch 44/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5130 - accuracy: 0.8662 - val_loss: 0.5544 - val_accuracy: 0.8625 - lr: 5.0000e-04\n",
            "Epoch 45/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5059 - accuracy: 0.8680 - val_loss: 0.5527 - val_accuracy: 0.8644 - lr: 5.0000e-04\n",
            "Epoch 46/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5053 - accuracy: 0.8696 - val_loss: 0.5381 - val_accuracy: 0.8680 - lr: 5.0000e-04\n",
            "Epoch 47/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5082 - accuracy: 0.8683 - val_loss: 0.5314 - val_accuracy: 0.8711 - lr: 5.0000e-04\n",
            "Epoch 48/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4962 - accuracy: 0.8723 - val_loss: 0.5375 - val_accuracy: 0.8676 - lr: 5.0000e-04\n",
            "Epoch 49/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5034 - accuracy: 0.8680 - val_loss: 0.5403 - val_accuracy: 0.8677 - lr: 5.0000e-04\n",
            "Epoch 50/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.5003 - accuracy: 0.8694 - val_loss: 0.5479 - val_accuracy: 0.8656 - lr: 5.0000e-04\n",
            "Epoch 51/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4945 - accuracy: 0.8717 - val_loss: 0.5255 - val_accuracy: 0.8691 - lr: 5.0000e-04\n",
            "Epoch 52/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4957 - accuracy: 0.8719 - val_loss: 0.4942 - val_accuracy: 0.8799 - lr: 5.0000e-04\n",
            "Epoch 53/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4987 - accuracy: 0.8704 - val_loss: 0.5137 - val_accuracy: 0.8747 - lr: 5.0000e-04\n",
            "Epoch 54/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4919 - accuracy: 0.8728 - val_loss: 0.5302 - val_accuracy: 0.8677 - lr: 5.0000e-04\n",
            "Epoch 55/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4901 - accuracy: 0.8731 - val_loss: 0.4935 - val_accuracy: 0.8762 - lr: 5.0000e-04\n",
            "Epoch 56/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4911 - accuracy: 0.8723 - val_loss: 0.5492 - val_accuracy: 0.8646 - lr: 5.0000e-04\n",
            "Epoch 57/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4878 - accuracy: 0.8733 - val_loss: 0.5150 - val_accuracy: 0.8731 - lr: 5.0000e-04\n",
            "Epoch 58/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4896 - accuracy: 0.8744 - val_loss: 0.5103 - val_accuracy: 0.8750 - lr: 5.0000e-04\n",
            "Epoch 59/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4895 - accuracy: 0.8730 - val_loss: 0.5358 - val_accuracy: 0.8644 - lr: 5.0000e-04\n",
            "Epoch 60/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4883 - accuracy: 0.8729 - val_loss: 0.4836 - val_accuracy: 0.8829 - lr: 5.0000e-04\n",
            "Epoch 61/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4819 - accuracy: 0.8754 - val_loss: 0.5070 - val_accuracy: 0.8764 - lr: 5.0000e-04\n",
            "Epoch 62/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4867 - accuracy: 0.8724 - val_loss: 0.5064 - val_accuracy: 0.8757 - lr: 5.0000e-04\n",
            "Epoch 63/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4811 - accuracy: 0.8729 - val_loss: 0.5447 - val_accuracy: 0.8646 - lr: 5.0000e-04\n",
            "Epoch 64/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4842 - accuracy: 0.8733 - val_loss: 0.5157 - val_accuracy: 0.8712 - lr: 5.0000e-04\n",
            "Epoch 65/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4815 - accuracy: 0.8755 - val_loss: 0.5463 - val_accuracy: 0.8625 - lr: 5.0000e-04\n",
            "Epoch 66/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4764 - accuracy: 0.8754 - val_loss: 0.4914 - val_accuracy: 0.8831 - lr: 5.0000e-04\n",
            "Epoch 67/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4761 - accuracy: 0.8768 - val_loss: 0.5286 - val_accuracy: 0.8681 - lr: 5.0000e-04\n",
            "Epoch 68/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4787 - accuracy: 0.8748 - val_loss: 0.5350 - val_accuracy: 0.8651 - lr: 5.0000e-04\n",
            "Epoch 69/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4788 - accuracy: 0.8750 - val_loss: 0.5388 - val_accuracy: 0.8667 - lr: 5.0000e-04\n",
            "Epoch 70/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4722 - accuracy: 0.8783 - val_loss: 0.5630 - val_accuracy: 0.8616 - lr: 5.0000e-04\n",
            "Epoch 71/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4760 - accuracy: 0.8759 - val_loss: 0.5114 - val_accuracy: 0.8746 - lr: 5.0000e-04\n",
            "Epoch 72/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4546 - accuracy: 0.8841 - val_loss: 0.4794 - val_accuracy: 0.8820 - lr: 3.0000e-04\n",
            "Epoch 73/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4458 - accuracy: 0.8881 - val_loss: 0.5162 - val_accuracy: 0.8719 - lr: 3.0000e-04\n",
            "Epoch 74/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4363 - accuracy: 0.8887 - val_loss: 0.4688 - val_accuracy: 0.8854 - lr: 3.0000e-04\n",
            "Epoch 75/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4375 - accuracy: 0.8882 - val_loss: 0.5018 - val_accuracy: 0.8757 - lr: 3.0000e-04\n",
            "Epoch 76/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4376 - accuracy: 0.8878 - val_loss: 0.5053 - val_accuracy: 0.8756 - lr: 3.0000e-04\n",
            "Epoch 77/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4291 - accuracy: 0.8912 - val_loss: 0.4751 - val_accuracy: 0.8812 - lr: 3.0000e-04\n",
            "Epoch 78/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4283 - accuracy: 0.8912 - val_loss: 0.4874 - val_accuracy: 0.8793 - lr: 3.0000e-04\n",
            "Epoch 79/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4248 - accuracy: 0.8913 - val_loss: 0.4797 - val_accuracy: 0.8807 - lr: 3.0000e-04\n",
            "Epoch 80/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4265 - accuracy: 0.8892 - val_loss: 0.4542 - val_accuracy: 0.8890 - lr: 3.0000e-04\n",
            "Epoch 81/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4220 - accuracy: 0.8906 - val_loss: 0.4611 - val_accuracy: 0.8880 - lr: 3.0000e-04\n",
            "Epoch 82/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4238 - accuracy: 0.8903 - val_loss: 0.4598 - val_accuracy: 0.8880 - lr: 3.0000e-04\n",
            "Epoch 83/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4246 - accuracy: 0.8896 - val_loss: 0.4489 - val_accuracy: 0.8912 - lr: 3.0000e-04\n",
            "Epoch 84/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4203 - accuracy: 0.8931 - val_loss: 0.4462 - val_accuracy: 0.8905 - lr: 3.0000e-04\n",
            "Epoch 85/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4158 - accuracy: 0.8920 - val_loss: 0.4344 - val_accuracy: 0.8921 - lr: 3.0000e-04\n",
            "Epoch 86/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4134 - accuracy: 0.8926 - val_loss: 0.4632 - val_accuracy: 0.8841 - lr: 3.0000e-04\n",
            "Epoch 87/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4170 - accuracy: 0.8914 - val_loss: 0.4648 - val_accuracy: 0.8866 - lr: 3.0000e-04\n",
            "Epoch 88/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4154 - accuracy: 0.8936 - val_loss: 0.4830 - val_accuracy: 0.8814 - lr: 3.0000e-04\n",
            "Epoch 89/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4102 - accuracy: 0.8935 - val_loss: 0.4623 - val_accuracy: 0.8833 - lr: 3.0000e-04\n",
            "Epoch 90/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4086 - accuracy: 0.8939 - val_loss: 0.4468 - val_accuracy: 0.8920 - lr: 3.0000e-04\n",
            "Epoch 91/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4109 - accuracy: 0.8928 - val_loss: 0.4960 - val_accuracy: 0.8788 - lr: 3.0000e-04\n",
            "Epoch 92/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4055 - accuracy: 0.8946 - val_loss: 0.5045 - val_accuracy: 0.8760 - lr: 3.0000e-04\n",
            "Epoch 93/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4072 - accuracy: 0.8931 - val_loss: 0.4582 - val_accuracy: 0.8849 - lr: 3.0000e-04\n",
            "Epoch 94/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4105 - accuracy: 0.8930 - val_loss: 0.4921 - val_accuracy: 0.8799 - lr: 3.0000e-04\n",
            "Epoch 95/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4059 - accuracy: 0.8934 - val_loss: 0.4627 - val_accuracy: 0.8858 - lr: 3.0000e-04\n",
            "Epoch 96/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4046 - accuracy: 0.8945 - val_loss: 0.4582 - val_accuracy: 0.8868 - lr: 3.0000e-04\n",
            "Epoch 97/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4063 - accuracy: 0.8926 - val_loss: 0.4391 - val_accuracy: 0.8908 - lr: 3.0000e-04\n",
            "Epoch 98/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4053 - accuracy: 0.8944 - val_loss: 0.4959 - val_accuracy: 0.8745 - lr: 3.0000e-04\n",
            "Epoch 99/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4069 - accuracy: 0.8944 - val_loss: 0.4915 - val_accuracy: 0.8773 - lr: 3.0000e-04\n",
            "Epoch 100/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4057 - accuracy: 0.8933 - val_loss: 0.4806 - val_accuracy: 0.8792 - lr: 3.0000e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fca1ad05310>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "def lr_schedule(epoch):\n",
        "    lrate = 0.001\n",
        "    if epoch > 30:\n",
        "        lrate = 0.0005\n",
        "    if epoch > 70:\n",
        "        lrate = 0.0003\n",
        "    return lrate\n",
        "\n",
        "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    )\n",
        "datagen.fit(x_train)\n",
        "\n",
        "batch_size = 64  \n",
        "epochs = 100\n",
        "\n",
        "model_2.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_2.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                    steps_per_epoch=x_train.shape[0]  // batch_size,epochs=epochs,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test),\\\n",
        "                    callbacks=[keras.callbacks.LearningRateScheduler(lr_schedule)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KbUqNMHqGpE0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cb7f888-bb9d-4be2-e225-fae134946e56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.4806486964225769\n",
            "Test accuracy: 0.8791999816894531\n"
          ]
        }
      ],
      "source": [
        "score = model_2.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "c69d141fca959081254a0b2e02e55787369c1159b7ddbc81e1232bfadcd3a9e7"
    },
    "kernelspec": {
      "display_name": "Python 3.10.3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    },
    "colab": {
      "name": "CNN_CIFAR-10_475.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}